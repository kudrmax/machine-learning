{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Считывание данных"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "outputs": [
    {
     "data": {
      "text/plain": "        year      name   percent   sex\n0       1880      John  0.081541   boy\n1       1880   William  0.080511   boy\n2       1880     James  0.050057   boy\n3       1880   Charles  0.045167   boy\n4       1880    George  0.043292   boy\n...      ...       ...       ...   ...\n257995  2008  Carleigh  0.000128  girl\n257996  2008     Iyana  0.000128  girl\n257997  2008    Kenley  0.000127  girl\n257998  2008    Sloane  0.000127  girl\n257999  2008   Elianna  0.000127  girl\n\n[258000 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>name</th>\n      <th>percent</th>\n      <th>sex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1880</td>\n      <td>John</td>\n      <td>0.081541</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1880</td>\n      <td>William</td>\n      <td>0.080511</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1880</td>\n      <td>James</td>\n      <td>0.050057</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1880</td>\n      <td>Charles</td>\n      <td>0.045167</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1880</td>\n      <td>George</td>\n      <td>0.043292</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>257995</th>\n      <td>2008</td>\n      <td>Carleigh</td>\n      <td>0.000128</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>257996</th>\n      <td>2008</td>\n      <td>Iyana</td>\n      <td>0.000128</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>257997</th>\n      <td>2008</td>\n      <td>Kenley</td>\n      <td>0.000127</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>257998</th>\n      <td>2008</td>\n      <td>Sloane</td>\n      <td>0.000127</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>257999</th>\n      <td>2008</td>\n      <td>Elianna</td>\n      <td>0.000127</td>\n      <td>girl</td>\n    </tr>\n  </tbody>\n</table>\n<p>258000 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"names.csv\")\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Разделение на тестовую и обучающую выборку"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "outputs": [],
   "source": [
    "data_train, data_test = train_test_split(data, test_size=0.3)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "outputs": [
    {
     "data": {
      "text/plain": "        year      name   percent   sex\n190170  1941      Lynn  0.001012  girl\n162345  1913     Molly  0.000301  girl\n214684  1965     Flora  0.000113  girl\n221982  1972  Julianna  0.000076  girl\n161221  1912     Jewel  0.000709  girl\n...      ...       ...       ...   ...\n189383  1940      Cleo  0.000255  girl\n216614  1967    Kerrie  0.000139  girl\n83674   1963   Carmine  0.000065   boy\n182476  1933     Merle  0.000174  girl\n109744  1989   Ulysses  0.000084   boy\n\n[77400 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>name</th>\n      <th>percent</th>\n      <th>sex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>190170</th>\n      <td>1941</td>\n      <td>Lynn</td>\n      <td>0.001012</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>162345</th>\n      <td>1913</td>\n      <td>Molly</td>\n      <td>0.000301</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>214684</th>\n      <td>1965</td>\n      <td>Flora</td>\n      <td>0.000113</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>221982</th>\n      <td>1972</td>\n      <td>Julianna</td>\n      <td>0.000076</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>161221</th>\n      <td>1912</td>\n      <td>Jewel</td>\n      <td>0.000709</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>189383</th>\n      <td>1940</td>\n      <td>Cleo</td>\n      <td>0.000255</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>216614</th>\n      <td>1967</td>\n      <td>Kerrie</td>\n      <td>0.000139</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>83674</th>\n      <td>1963</td>\n      <td>Carmine</td>\n      <td>0.000065</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>182476</th>\n      <td>1933</td>\n      <td>Merle</td>\n      <td>0.000174</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>109744</th>\n      <td>1989</td>\n      <td>Ulysses</td>\n      <td>0.000084</td>\n      <td>boy</td>\n    </tr>\n  </tbody>\n</table>\n<p>77400 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "outputs": [
    {
     "data": {
      "text/plain": "        year      name   percent   sex\n39244   1919    Murray  0.000457   boy\n144187  1895     Selma  0.000842  girl\n166943  1917    Thomas  0.000049  girl\n196026  1947    Gloria  0.006936  girl\n198301  1949  Gertrude  0.000373  girl\n...      ...       ...       ...   ...\n436     1880     Merle  0.000144   boy\n59761   1939      Theo  0.000057   boy\n116578  1996   Vicente  0.000157   boy\n249707  2000    Rebeca  0.000165  girl\n125809  2005     Kylan  0.000110   boy\n\n[180600 rows x 4 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>year</th>\n      <th>name</th>\n      <th>percent</th>\n      <th>sex</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>39244</th>\n      <td>1919</td>\n      <td>Murray</td>\n      <td>0.000457</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>144187</th>\n      <td>1895</td>\n      <td>Selma</td>\n      <td>0.000842</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>166943</th>\n      <td>1917</td>\n      <td>Thomas</td>\n      <td>0.000049</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>196026</th>\n      <td>1947</td>\n      <td>Gloria</td>\n      <td>0.006936</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>198301</th>\n      <td>1949</td>\n      <td>Gertrude</td>\n      <td>0.000373</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>436</th>\n      <td>1880</td>\n      <td>Merle</td>\n      <td>0.000144</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>59761</th>\n      <td>1939</td>\n      <td>Theo</td>\n      <td>0.000057</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>116578</th>\n      <td>1996</td>\n      <td>Vicente</td>\n      <td>0.000157</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>249707</th>\n      <td>2000</td>\n      <td>Rebeca</td>\n      <td>0.000165</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>125809</th>\n      <td>2005</td>\n      <td>Kylan</td>\n      <td>0.000110</td>\n      <td>boy</td>\n    </tr>\n  </tbody>\n</table>\n<p>180600 rows × 4 columns</p>\n</div>"
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Функция для наивной байесовской классификации"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from math import log\n",
    "\n",
    "\n",
    "def train(samples):\n",
    "    \"\"\"\n",
    "    Функция для обучения модели\n",
    "    \"\"\"\n",
    "    classes, freq = defaultdict(lambda: 0), defaultdict(lambda: 0) # классы и частоты\n",
    "\n",
    "    # заполняем словари из классов и частот\n",
    "    for feats, label in samples: # идем по признакам (feats) и полам (label)\n",
    "        classes[label] += 1  # count classes frequencies\n",
    "        for feat in feats:\n",
    "            freq[label, feat] += 1  # count features frequencies\n",
    "\n",
    "    # превращаем count в количество\n",
    "    for label, feat in freq:  # normalize features frequencies\n",
    "        freq[label, feat] /= classes[label]\n",
    "    for c in classes:  # normalize classes frequencies\n",
    "        classes[c] /= len(samples)\n",
    "\n",
    "    return classes, freq  # return P(C) and P(O|C)\n",
    "\n",
    "\n",
    "def classify(classifier, feats):\n",
    "    \"\"\"\n",
    "    Функция для классификации\n",
    "    \"\"\"\n",
    "    classes, prob = classifier\n",
    "    return min(classes.keys(),  # calculate argmin(-log(P(C|O))) -> argmax(P(C|O))\n",
    "           key=lambda cl: -log(classes[cl]) \\\n",
    "                          + sum(-log(prob.get((cl, feat))) if (cl, feat) in prob else 0 for feat in feats))\n",
    "\n",
    "def get_features(sample: str):\n",
    "    \"\"\"\n",
    "    Функция для превращения слова в признак.\n",
    "    Признак: последняя буква.\n",
    "    \"\"\"\n",
    "    return sample[-1]  # get last letter"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Применение функции"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "outputs": [
    {
     "data": {
      "text/plain": "[['y', 'boy'],\n ['a', 'girl'],\n ['s', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['t', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['n', 'girl'],\n ['y', 'girl'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['y', 'boy'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['l', 'boy'],\n ['h', 'girl'],\n ['e', 'girl'],\n ['x', 'boy'],\n ['e', 'girl'],\n ['e', 'boy'],\n ['e', 'girl'],\n ['r', 'boy'],\n ['t', 'girl'],\n ['a', 'girl'],\n ['s', 'girl'],\n ['n', 'boy'],\n ['n', 'boy'],\n ['d', 'boy'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['r', 'boy'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['l', 'girl'],\n ['d', 'boy'],\n ['a', 'girl'],\n ['y', 'girl'],\n ['y', 'boy'],\n ['y', 'boy'],\n ['o', 'girl'],\n ['e', 'girl'],\n ['m', 'boy'],\n ['s', 'boy'],\n ['d', 'boy'],\n ['r', 'boy'],\n ['h', 'boy'],\n ['a', 'girl'],\n ['y', 'boy'],\n ['k', 'boy'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['y', 'girl'],\n ['l', 'boy'],\n ['e', 'boy'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['e', 'boy'],\n ['s', 'boy'],\n ['n', 'boy'],\n ['r', 'boy'],\n ['r', 'girl'],\n ['r', 'boy'],\n ['l', 'girl'],\n ['y', 'girl'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['l', 'boy'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['r', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['d', 'boy'],\n ['a', 'girl'],\n ['y', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['y', 'boy'],\n ['a', 'girl'],\n ['n', 'girl'],\n ['a', 'girl'],\n ['z', 'girl'],\n ['y', 'boy'],\n ['l', 'boy'],\n ['o', 'boy'],\n ['r', 'girl'],\n ['e', 'girl'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['n', 'boy'],\n ['r', 'boy'],\n ['n', 'girl'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['r', 'boy'],\n ['r', 'girl'],\n ['d', 'boy'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['l', 'boy'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['a', 'boy'],\n ['y', 'girl'],\n ['l', 'boy'],\n ['y', 'boy'],\n ['o', 'boy'],\n ['r', 'boy'],\n ['l', 'boy'],\n ['l', 'boy'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['t', 'boy'],\n ['n', 'girl'],\n ['h', 'girl'],\n ['a', 'girl'],\n ['r', 'girl'],\n ['y', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['n', 'girl'],\n ['y', 'boy'],\n ['e', 'girl'],\n ['y', 'girl'],\n ['y', 'boy'],\n ['d', 'boy'],\n ['s', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['n', 'girl'],\n ['l', 'girl'],\n ['e', 'girl'],\n ['d', 'girl'],\n ['n', 'boy'],\n ['h', 'girl'],\n ['e', 'girl'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['d', 'boy'],\n ['t', 'boy'],\n ['e', 'girl'],\n ['o', 'boy'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['y', 'girl'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['x', 'boy'],\n ['e', 'girl'],\n ['m', 'boy'],\n ['s', 'boy'],\n ['t', 'boy'],\n ['n', 'boy'],\n ['t', 'boy'],\n ['r', 'boy'],\n ['e', 'girl'],\n ['d', 'boy'],\n ['m', 'boy'],\n ['l', 'girl'],\n ['o', 'boy'],\n ['y', 'girl'],\n ['y', 'boy'],\n ['k', 'boy'],\n ['y', 'boy'],\n ['n', 'girl'],\n ['o', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['t', 'boy'],\n ['e', 'boy'],\n ['s', 'girl'],\n ['k', 'boy'],\n ['h', 'girl'],\n ['n', 'boy'],\n ['n', 'boy'],\n ['t', 'girl'],\n ['e', 'boy'],\n ['r', 'boy'],\n ['n', 'boy'],\n ['d', 'boy'],\n ['y', 'boy'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['y', 'boy'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['e', 'boy'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['l', 'girl'],\n ['e', 'girl'],\n ['t', 'girl'],\n ['a', 'girl'],\n ['r', 'boy'],\n ['m', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['y', 'boy'],\n ['r', 'boy'],\n ['n', 'boy'],\n ['y', 'girl'],\n ['n', 'boy'],\n ['t', 'girl'],\n ['n', 'girl'],\n ['e', 'boy'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['y', 'girl'],\n ['y', 'girl'],\n ['a', 'girl'],\n ['t', 'girl'],\n ['e', 'girl'],\n ['k', 'boy'],\n ['n', 'boy'],\n ['r', 'boy'],\n ['e', 'boy'],\n ['h', 'girl'],\n ['s', 'boy'],\n ['t', 'boy'],\n ['y', 'girl'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['e', 'boy'],\n ['s', 'boy'],\n ['n', 'boy'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['o', 'boy'],\n ['y', 'girl'],\n ['a', 'girl'],\n ['e', 'boy'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['n', 'boy'],\n ['t', 'boy'],\n ['e', 'girl'],\n ['f', 'boy'],\n ['o', 'boy'],\n ['t', 'girl'],\n ['e', 'girl'],\n ['d', 'boy'],\n ['o', 'girl'],\n ['e', 'girl'],\n ['e', 'boy'],\n ['y', 'girl'],\n ['y', 'boy'],\n ['n', 'boy'],\n ['n', 'boy'],\n ['n', 'boy'],\n ['k', 'boy'],\n ['y', 'girl'],\n ['n', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['e', 'boy'],\n ['m', 'girl'],\n ['s', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['t', 'boy'],\n ['a', 'girl'],\n ['y', 'boy'],\n ['a', 'girl'],\n ['g', 'boy'],\n ['h', 'boy'],\n ['y', 'girl'],\n ['y', 'boy'],\n ['y', 'boy'],\n ['y', 'boy'],\n ['l', 'boy'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['t', 'boy'],\n ['e', 'boy'],\n ['l', 'boy'],\n ['a', 'boy'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['e', 'boy'],\n ['y', 'girl'],\n ['d', 'boy'],\n ['n', 'girl'],\n ['e', 'girl'],\n ['e', 'boy'],\n ['l', 'boy'],\n ['y', 'girl'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['e', 'boy'],\n ['y', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['d', 'boy'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['o', 'boy'],\n ['e', 'girl'],\n ['l', 'boy'],\n ['n', 'boy'],\n ['y', 'boy'],\n ['r', 'boy'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['l', 'girl'],\n ['s', 'boy'],\n ['a', 'boy'],\n ['a', 'girl'],\n ['y', 'boy'],\n ['o', 'boy'],\n ['n', 'boy'],\n ['r', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['y', 'boy'],\n ['n', 'boy'],\n ['e', 'boy'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['m', 'boy'],\n ['t', 'girl'],\n ['e', 'boy'],\n ['d', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['y', 'boy'],\n ['t', 'boy'],\n ['l', 'boy'],\n ['y', 'boy'],\n ['r', 'boy'],\n ['r', 'boy'],\n ['n', 'boy'],\n ['y', 'girl'],\n ['l', 'boy'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['m', 'boy'],\n ['e', 'girl'],\n ['d', 'girl'],\n ['n', 'boy'],\n ['t', 'boy'],\n ['a', 'boy'],\n ['d', 'boy'],\n ['e', 'girl'],\n ['a', 'boy'],\n ['y', 'boy'],\n ['s', 'boy'],\n ['y', 'boy'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['m', 'boy'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['y', 'girl'],\n ['k', 'boy'],\n ['k', 'boy'],\n ['e', 'boy'],\n ['e', 'boy'],\n ['y', 'girl'],\n ['y', 'girl'],\n ['a', 'girl'],\n ['r', 'boy'],\n ['a', 'girl'],\n ['r', 'boy'],\n ['l', 'girl'],\n ['d', 'boy'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['l', 'boy'],\n ['y', 'boy'],\n ['r', 'boy'],\n ['e', 'boy'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['n', 'girl'],\n ['n', 'boy'],\n ['r', 'boy'],\n ['d', 'boy'],\n ['i', 'boy'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['i', 'girl'],\n ['n', 'boy'],\n ['a', 'girl'],\n ['r', 'girl'],\n ['h', 'girl'],\n ['a', 'girl'],\n ['h', 'girl'],\n ['z', 'boy'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['n', 'girl'],\n ['l', 'boy'],\n ['e', 'boy'],\n ['y', 'girl'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['i', 'girl'],\n ['t', 'boy'],\n ['a', 'girl'],\n ['y', 'boy'],\n ['y', 'girl'],\n ['t', 'boy'],\n ['a', 'girl'],\n ['h', 'boy'],\n ['a', 'girl'],\n ['o', 'girl'],\n ['y', 'boy'],\n ['a', 'girl'],\n ['h', 'boy'],\n ['n', 'boy'],\n ['h', 'girl'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['a', 'girl'],\n ['s', 'boy'],\n ['s', 'boy'],\n ['n', 'boy'],\n ['o', 'boy'],\n ['y', 'girl'],\n ['n', 'boy'],\n ['a', 'girl'],\n ['y', 'boy'],\n ['a', 'girl'],\n ['s', 'boy'],\n ['a', 'girl'],\n ['n', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['e', 'boy'],\n ['y', 'girl'],\n ['r', 'boy'],\n ['h', 'girl'],\n ['d', 'boy'],\n ['r', 'boy'],\n ['n', 'boy'],\n ['n', 'boy'],\n ['h', 'girl'],\n ['t', 'girl'],\n ['l', 'boy'],\n ['a', 'girl'],\n ['s', 'boy'],\n ['d', 'boy'],\n ['d', 'girl'],\n ['r', 'boy'],\n ['y', 'boy'],\n ['d', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['n', 'girl'],\n ['d', 'boy'],\n ['e', 'girl'],\n ['s', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['s', 'boy'],\n ['n', 'boy'],\n ['s', 'boy'],\n ['e', 'girl'],\n ['s', 'girl'],\n ['v', 'boy'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['y', 'boy'],\n ['e', 'girl'],\n ['m', 'boy'],\n ['a', 'girl'],\n ['y', 'girl'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['l', 'girl'],\n ['d', 'girl'],\n ['n', 'boy'],\n ['h', 'girl'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['y', 'boy'],\n ['r', 'boy'],\n ['e', 'girl'],\n ['t', 'boy'],\n ['l', 'boy'],\n ['n', 'girl'],\n ['e', 'girl'],\n ['s', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['y', 'boy'],\n ['n', 'boy'],\n ['t', 'boy'],\n ['y', 'boy'],\n ['s', 'boy'],\n ['o', 'boy'],\n ['d', 'boy'],\n ['d', 'boy'],\n ['m', 'boy'],\n ['a', 'girl'],\n ['h', 'boy'],\n ['e', 'girl'],\n ['k', 'boy'],\n ['f', 'boy'],\n ['e', 'girl'],\n ['s', 'girl'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['a', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['y', 'boy'],\n ['n', 'boy'],\n ['l', 'boy'],\n ['z', 'girl'],\n ['n', 'boy'],\n ['l', 'boy'],\n ['e', 'boy'],\n ['d', 'boy'],\n ['w', 'boy'],\n ['t', 'boy'],\n ['r', 'boy'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['n', 'girl'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['y', 'boy'],\n ['d', 'boy'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['y', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['l', 'boy'],\n ['n', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['y', 'boy'],\n ['n', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['n', 'girl'],\n ['e', 'girl'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['t', 'boy'],\n ['a', 'girl'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['r', 'boy'],\n ['h', 'girl'],\n ['s', 'boy'],\n ['e', 'boy'],\n ['s', 'boy'],\n ['n', 'boy'],\n ['n', 'boy'],\n ['l', 'girl'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['g', 'boy'],\n ['y', 'boy'],\n ['n', 'boy'],\n ['e', 'boy'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['r', 'boy'],\n ['g', 'boy'],\n ['h', 'girl'],\n ['n', 'boy'],\n ['t', 'boy'],\n ['n', 'boy'],\n ['s', 'boy'],\n ['n', 'boy'],\n ['y', 'boy'],\n ['n', 'boy'],\n ['e', 'boy'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['y', 'girl'],\n ['e', 'boy'],\n ['h', 'boy'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['e', 'boy'],\n ['s', 'boy'],\n ['a', 'girl'],\n ['y', 'girl'],\n ['l', 'boy'],\n ['s', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['o', 'boy'],\n ['e', 'boy'],\n ['o', 'boy'],\n ['d', 'boy'],\n ['s', 'boy'],\n ['n', 'boy'],\n ['y', 'boy'],\n ['s', 'boy'],\n ['t', 'boy'],\n ['y', 'boy'],\n ['k', 'boy'],\n ['e', 'boy'],\n ['r', 'boy'],\n ['e', 'boy'],\n ['r', 'boy'],\n ['y', 'girl'],\n ['l', 'boy'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['r', 'boy'],\n ['m', 'boy'],\n ['y', 'girl'],\n ['l', 'boy'],\n ['n', 'girl'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['b', 'boy'],\n ['i', 'girl'],\n ['y', 'girl'],\n ['n', 'boy'],\n ['n', 'girl'],\n ['y', 'boy'],\n ['n', 'boy'],\n ['t', 'boy'],\n ['f', 'boy'],\n ['n', 'girl'],\n ['r', 'boy'],\n ['e', 'boy'],\n ['o', 'boy'],\n ['y', 'girl'],\n ['k', 'boy'],\n ['i', 'girl'],\n ['y', 'girl'],\n ['e', 'girl'],\n ['h', 'boy'],\n ['y', 'boy'],\n ['n', 'boy'],\n ['o', 'boy'],\n ['a', 'boy'],\n ['a', 'girl'],\n ['l', 'boy'],\n ['o', 'boy'],\n ['e', 'girl'],\n ['i', 'girl'],\n ['e', 'girl'],\n ['l', 'boy'],\n ['n', 'boy'],\n ['s', 'boy'],\n ['y', 'boy'],\n ['n', 'girl'],\n ['y', 'girl'],\n ['y', 'boy'],\n ['s', 'boy'],\n ['r', 'boy'],\n ['n', 'boy'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['l', 'girl'],\n ['l', 'girl'],\n ['h', 'girl'],\n ['e', 'boy'],\n ['i', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['h', 'boy'],\n ['e', 'girl'],\n ['y', 'girl'],\n ['r', 'boy'],\n ['n', 'boy'],\n ['n', 'boy'],\n ['m', 'boy'],\n ['y', 'girl'],\n ['y', 'girl'],\n ['a', 'girl'],\n ['a', 'boy'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['m', 'boy'],\n ['d', 'boy'],\n ['l', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['n', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['y', 'boy'],\n ['y', 'boy'],\n ['l', 'boy'],\n ['e', 'girl'],\n ['k', 'boy'],\n ['e', 'girl'],\n ['n', 'girl'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['h', 'girl'],\n ['n', 'girl'],\n ['y', 'boy'],\n ['i', 'boy'],\n ['a', 'girl'],\n ['y', 'girl'],\n ['n', 'boy'],\n ['g', 'boy'],\n ['l', 'boy'],\n ['r', 'boy'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['d', 'boy'],\n ['e', 'boy'],\n ['l', 'boy'],\n ['a', 'girl'],\n ['t', 'boy'],\n ['y', 'boy'],\n ['s', 'boy'],\n ['l', 'boy'],\n ['n', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['r', 'boy'],\n ['y', 'boy'],\n ['e', 'boy'],\n ['o', 'boy'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['a', 'boy'],\n ['e', 'girl'],\n ['r', 'boy'],\n ['n', 'boy'],\n ['y', 'boy'],\n ['r', 'boy'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['e', 'boy'],\n ['e', 'boy'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['a', 'girl'],\n ['l', 'boy'],\n ['r', 'boy'],\n ['r', 'boy'],\n ['s', 'boy'],\n ['l', 'boy'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['a', 'boy'],\n ['a', 'girl'],\n ['l', 'boy'],\n ['h', 'girl'],\n ['e', 'boy'],\n ['y', 'boy'],\n ['s', 'boy'],\n ['d', 'girl'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['g', 'boy'],\n ['l', 'girl'],\n ['i', 'girl'],\n ['r', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['o', 'boy'],\n ['n', 'boy'],\n ['n', 'girl'],\n ['e', 'boy'],\n ['n', 'boy'],\n ['a', 'girl'],\n ['o', 'boy'],\n ['t', 'boy'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['n', 'boy'],\n ['n', 'boy'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['m', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['k', 'boy'],\n ['o', 'boy'],\n ['a', 'girl'],\n ['c', 'boy'],\n ['n', 'girl'],\n ['t', 'boy'],\n ['i', 'boy'],\n ['e', 'girl'],\n ['n', 'girl'],\n ['n', 'boy'],\n ['e', 'boy'],\n ['s', 'boy'],\n ['z', 'boy'],\n ['a', 'girl'],\n ['l', 'boy'],\n ['a', 'girl'],\n ['h', 'girl'],\n ['e', 'boy'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['l', 'boy'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['h', 'boy'],\n ['h', 'boy'],\n ['y', 'boy'],\n ['d', 'boy'],\n ['y', 'girl'],\n ['y', 'girl'],\n ['a', 'girl'],\n ['n', 'girl'],\n ['a', 'boy'],\n ['e', 'girl'],\n ['o', 'boy'],\n ['o', 'boy'],\n ['y', 'boy'],\n ['e', 'girl'],\n ['l', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['s', 'boy'],\n ['k', 'boy'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['y', 'boy'],\n ['e', 'boy'],\n ['a', 'boy'],\n ['e', 'girl'],\n ['y', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['e', 'boy'],\n ['i', 'girl'],\n ['y', 'girl'],\n ['a', 'girl'],\n ['e', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['n', 'boy'],\n ['d', 'boy'],\n ['n', 'boy'],\n ['l', 'girl'],\n ['s', 'girl'],\n ['s', 'girl'],\n ['s', 'girl'],\n ['t', 'boy'],\n ['l', 'boy'],\n ['s', 'boy'],\n ['y', 'boy'],\n ['k', 'boy'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['s', 'girl'],\n ['y', 'boy'],\n ['a', 'girl'],\n ['n', 'girl'],\n ['y', 'boy'],\n ['n', 'boy'],\n ['r', 'boy'],\n ['n', 'boy'],\n ['e', 'boy'],\n ['l', 'girl'],\n ['h', 'girl'],\n ['o', 'boy'],\n ['a', 'girl'],\n ['o', 'boy'],\n ['k', 'boy'],\n ['o', 'boy'],\n ['d', 'boy'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['n', 'boy'],\n ['y', 'girl'],\n ['e', 'girl'],\n ['d', 'girl'],\n ['n', 'boy'],\n ['y', 'girl'],\n ['e', 'boy'],\n ['l', 'boy'],\n ['n', 'boy'],\n ['e', 'boy'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['l', 'girl'],\n ['y', 'boy'],\n ['n', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['d', 'boy'],\n ['s', 'girl'],\n ['e', 'boy'],\n ['e', 'girl'],\n ['e', 'girl'],\n ['a', 'girl'],\n ['a', 'girl'],\n ['y', 'boy'],\n ['y', 'boy'],\n ['a', 'girl'],\n ['e', 'boy'],\n ['a', 'girl'],\n ['e', 'girl'],\n ['s', 'boy'],\n ['e', 'girl'],\n ['m', 'boy'],\n ['y', 'boy'],\n ['n', 'boy'],\n ['e', 'girl'],\n ['y', 'boy'],\n ['y', 'boy'],\n ['y', 'boy'],\n ['e', 'boy'],\n ['y', 'girl'],\n ['n', 'boy'],\n ['r', 'boy'],\n ['l', 'boy'],\n ['e', 'boy'],\n ['s', 'boy'],\n ['o', 'boy'],\n ['n', 'boy'],\n ['a', 'girl'],\n ...]"
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучение\n",
    "samples = [[get_features(name), lable] for name, lable in zip(data_train['name'], data_train['sex'])]\n",
    "samples"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "outputs": [
    {
     "data": {
      "text/plain": "(defaultdict(<function __main__.train.<locals>.<lambda>()>,\n             {'boy': 0.4998449612403101, 'girl': 0.5001550387596899}),\n defaultdict(<function __main__.train.<locals>.<lambda>()>,\n             {('boy', 'y'): 0.11165145338532435,\n              ('girl', 'a'): 0.38392303604640865,\n              ('girl', 's'): 0.022362943937649454,\n              ('girl', 'e'): 0.30275219201133646,\n              ('boy', 't'): 0.05229750088621057,\n              ('girl', 'n'): 0.08024089983172439,\n              ('girl', 'y'): 0.07858028518288902,\n              ('boy', 'n'): 0.21423032612548742,\n              ('boy', 'l'): 0.08299361928394186,\n              ('girl', 'h'): 0.024787441324949075,\n              ('boy', 'x'): 0.004375664657922723,\n              ('boy', 'e'): 0.1392126019142148,\n              ('boy', 'r'): 0.060461715703651185,\n              ('girl', 't'): 0.010971127446638916,\n              ('boy', 'd'): 0.0722040056717476,\n              ('girl', 'l'): 0.03469577539633336,\n              ('girl', 'o'): 0.005225400761668586,\n              ('boy', 'm'): 0.016173342786246013,\n              ('boy', 's'): 0.07896136121942574,\n              ('boy', 'h'): 0.02629829847571783,\n              ('boy', 'k'): 0.022609447004608294,\n              ('girl', 'r'): 0.012044991586219113,\n              ('girl', 'z'): 0.0019041714639978745,\n              ('boy', 'o'): 0.06255538816022686,\n              ('boy', 'a'): 0.016084721729883022,\n              ('girl', 'd'): 0.00803737490036312,\n              ('boy', 'f'): 0.003500531726338178,\n              ('girl', 'm'): 0.0030444601895314853,\n              ('boy', 'g'): 0.006004076568592698,\n              ('boy', 'i'): 0.005317263381779511,\n              ('girl', 'i'): 0.027245151005225402,\n              ('boy', 'z'): 0.002259836937256292,\n              ('boy', 'v'): 0.00048741580999645516,\n              ('boy', 'w'): 0.004896313364055299,\n              ('boy', 'b'): 0.0038328606876993974,\n              ('boy', 'c'): 0.009260900389932648,\n              ('boy', 'p'): 0.0032125132931584543,\n              ('boy', 'j'): 0.00011077632045373981,\n              ('girl', 'g'): 0.0005424674519528828,\n              ('girl', 'u'): 0.0016384731201842175,\n              ('girl', 'k'): 0.0009188734390222301,\n              ('girl', 'x'): 0.00022141528651138074,\n              ('boy', 'u'): 0.0008751329315845445,\n              ('girl', 'w'): 0.00046497210167389957,\n              ('boy', 'q'): 0.00013293158454448777,\n              ('girl', 'c'): 0.00027676910813922593,\n              ('girl', 'b'): 9.963687893012133e-05,\n              ('girl', 'v'): 2.2141528651138074e-05}))"
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = train(samples)\n",
    "classifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max is a boy\n",
      "Nikita is a girl\n",
      "Vika is a girl\n"
     ]
    }
   ],
   "source": [
    "# проверка\n",
    "names = ['Max', 'Nikita', 'Vika']\n",
    "for name in names:\n",
    "    print(f\"{name} is a {classify(classifier, get_features(name))}\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "outputs": [
    {
     "data": {
      "text/plain": "            name   sex class\n190170      Lynn  girl   boy\n162345     Molly  girl   boy\n214684     Flora  girl  girl\n221982  Julianna  girl  girl\n161221     Jewel  girl   boy\n...          ...   ...   ...\n189383      Cleo  girl   boy\n216614    Kerrie  girl  girl\n83674    Carmine   boy  girl\n182476     Merle  girl  girl\n109744   Ulysses   boy   boy\n\n[77400 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>sex</th>\n      <th>class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>190170</th>\n      <td>Lynn</td>\n      <td>girl</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>162345</th>\n      <td>Molly</td>\n      <td>girl</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>214684</th>\n      <td>Flora</td>\n      <td>girl</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>221982</th>\n      <td>Julianna</td>\n      <td>girl</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>161221</th>\n      <td>Jewel</td>\n      <td>girl</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>189383</th>\n      <td>Cleo</td>\n      <td>girl</td>\n      <td>boy</td>\n    </tr>\n    <tr>\n      <th>216614</th>\n      <td>Kerrie</td>\n      <td>girl</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>83674</th>\n      <td>Carmine</td>\n      <td>boy</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>182476</th>\n      <td>Merle</td>\n      <td>girl</td>\n      <td>girl</td>\n    </tr>\n    <tr>\n      <th>109744</th>\n      <td>Ulysses</td>\n      <td>boy</td>\n      <td>boy</td>\n    </tr>\n  </tbody>\n</table>\n<p>77400 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test['class'] = [classify(classifier, get_features(name)) for name in data_test['name']]\n",
    "data_test[['name', 'sex', 'class']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Точность"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Через частоту"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7752454780361757"
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вручную\n",
    "accuracy = sum([sex == cl for sex, cl in zip(data_test['sex'], data_test['class'])]) / data_test.shape[0]\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7752454780361757"
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy = sklearn.metrics.accuracy_score(data_test['sex'], data_test['class'])\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Через полноту"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "outputs": [
    {
     "data": {
      "text/plain": "[0.8344866763065483, 0.7159184940008275]"
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# вручную\n",
    "\n",
    "recall = [0, 0]\n",
    "\n",
    "# насколько верно он определяет мужские имена\n",
    "sex = 'boy'\n",
    "recall[0] = data_test.loc[data_test['sex'].str.contains(sex) & data_test['class'].str.contains(sex)].shape[0] / data_test.loc[data_test['sex'].str.contains(sex)].shape[0]\n",
    "\n",
    "# насколько верно он определяет мужские имена\n",
    "sex = 'girl'\n",
    "recall[1] = data_test.loc[data_test['sex'].str.contains(sex) & data_test['class'].str.contains(sex)].shape[0] / data_test.loc[data_test['sex'].str.contains(sex)].shape[0]\n",
    "\n",
    "recall"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "outputs": [
    {
     "data": {
      "text/plain": "(array([0.83448668, 0.71591849]),)"
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# автоматически\n",
    "\n",
    "sklearn.metrics.recall_score(data_test['sex'], data_test['class'], average=None),"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Изменим get_features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7007364341085272"
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_features(sample: str):\n",
    "    \"\"\"\n",
    "    Функция для превращения слова в признак.\n",
    "    Признак: последние 2 буквы.\n",
    "    \"\"\"\n",
    "    return sample[-2:]  # get last letter\n",
    "\n",
    "samples = [[get_features(name), lable] for name, lable in zip(data_train['name'], data_train['sex'])]\n",
    "classifier = train(samples)\n",
    "data_test['class'] = [classify(classifier, get_features(name)) for name in data_test['name']]\n",
    "accuracy = sklearn.metrics.accuracy_score(data_test['sex'], data_test['class'])\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7107235142118863"
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_features(sample: str):\n",
    "    \"\"\"\n",
    "    Функция для превращения слова в признак.\n",
    "    Признак: Первая + последняя буквы.\n",
    "    \"\"\"\n",
    "    return sample[1] + sample[-1]  # get last letter\n",
    "\n",
    "samples = [[get_features(name), lable] for name, lable in zip(data_train['name'], data_train['sex'])]\n",
    "classifier = train(samples)\n",
    "data_test['class'] = [classify(classifier, get_features(name)) for name in data_test['name']]\n",
    "accuracy = sklearn.metrics.accuracy_score(data_test['sex'], data_test['class'])\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Изменим classify"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "outputs": [
    {
     "data": {
      "text/plain": "0.674031007751938"
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def classify(classifier, feats):\n",
    "    \"\"\"\n",
    "    Функция для классификации\n",
    "    \"\"\"\n",
    "    classes, prob = classifier\n",
    "    return max(classes.keys(),\n",
    "           key=lambda cl: log(classes[cl]) \\\n",
    "                          + sum(prob.get((cl, feat)) if (cl, feat) in prob else 0 for feat in feats))\n",
    "\n",
    "samples = [[get_features(name), lable] for name, lable in zip(data_train['name'], data_train['sex'])]\n",
    "classifier = train(samples)\n",
    "data_test['class'] = [classify(classifier, get_features(name)) for name in data_test['name']]\n",
    "accuracy = sklearn.metrics.accuracy_score(data_test['sex'], data_test['class'])\n",
    "accuracy"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Видно, что точность упала"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# sklearn.naive_bayes"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'Murray'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[310], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnaive_bayes\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GaussianNB\n\u001B[1;32m      3\u001B[0m gnb \u001B[38;5;241m=\u001B[39m GaussianNB()\n\u001B[0;32m----> 4\u001B[0m data_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mgnb\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_train\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mname\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata_train\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msex\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mpredict(data_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of mislabeled points out of a total \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m points : \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m (data_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], (data_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msex\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m!=\u001B[39m data_train[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mclass\u001B[39m\u001B[38;5;124m'\u001B[39m])\u001B[38;5;241m.\u001B[39msum()))\n",
      "File \u001B[0;32m~/PycharmProjects/ml-hse/venv/lib/python3.11/site-packages/sklearn/base.py:1474\u001B[0m, in \u001B[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001B[0;34m(estimator, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1467\u001B[0m     estimator\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[1;32m   1469\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m config_context(\n\u001B[1;32m   1470\u001B[0m     skip_parameter_validation\u001B[38;5;241m=\u001B[39m(\n\u001B[1;32m   1471\u001B[0m         prefer_skip_nested_validation \u001B[38;5;129;01mor\u001B[39;00m global_skip_validation\n\u001B[1;32m   1472\u001B[0m     )\n\u001B[1;32m   1473\u001B[0m ):\n\u001B[0;32m-> 1474\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfit_method\u001B[49m\u001B[43m(\u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ml-hse/venv/lib/python3.11/site-packages/sklearn/naive_bayes.py:263\u001B[0m, in \u001B[0;36mGaussianNB.fit\u001B[0;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[1;32m    240\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fit Gaussian Naive Bayes according to X, y.\u001B[39;00m\n\u001B[1;32m    241\u001B[0m \n\u001B[1;32m    242\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    260\u001B[0m \u001B[38;5;124;03m    Returns the instance itself.\u001B[39;00m\n\u001B[1;32m    261\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    262\u001B[0m y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(y\u001B[38;5;241m=\u001B[39my)\n\u001B[0;32m--> 263\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_partial_fit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munique\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_refit\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\n\u001B[1;32m    265\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/PycharmProjects/ml-hse/venv/lib/python3.11/site-packages/sklearn/naive_bayes.py:423\u001B[0m, in \u001B[0;36mGaussianNB._partial_fit\u001B[0;34m(self, X, y, classes, _refit, sample_weight)\u001B[0m\n\u001B[1;32m    420\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    422\u001B[0m first_call \u001B[38;5;241m=\u001B[39m _check_partial_fit_first_call(\u001B[38;5;28mself\u001B[39m, classes)\n\u001B[0;32m--> 423\u001B[0m X, y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfirst_call\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    424\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    425\u001B[0m     sample_weight \u001B[38;5;241m=\u001B[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001B[0;32m~/PycharmProjects/ml-hse/venv/lib/python3.11/site-packages/sklearn/base.py:650\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[1;32m    648\u001B[0m         y \u001B[38;5;241m=\u001B[39m check_array(y, input_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_y_params)\n\u001B[1;32m    649\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 650\u001B[0m         X, y \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_X_y\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mcheck_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    651\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    653\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n",
      "File \u001B[0;32m~/PycharmProjects/ml-hse/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:1263\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m   1258\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[1;32m   1259\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1260\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1261\u001B[0m     )\n\u001B[0;32m-> 1263\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1264\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1265\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1266\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1267\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1268\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1269\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1270\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1271\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1272\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1273\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1274\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1275\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1276\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1277\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1279\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[1;32m   1281\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[0;32m~/PycharmProjects/ml-hse/venv/lib/python3.11/site-packages/sklearn/utils/validation.py:997\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    995\u001B[0m         array \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(array, dtype, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    996\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 997\u001B[0m         array \u001B[38;5;241m=\u001B[39m \u001B[43m_asarray_with_order\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mxp\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mxp\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    998\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ComplexWarning \u001B[38;5;28;01mas\u001B[39;00m complex_warning:\n\u001B[1;32m    999\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1000\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mComplex data not supported\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[1;32m   1001\u001B[0m     ) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcomplex_warning\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/ml-hse/venv/lib/python3.11/site-packages/sklearn/utils/_array_api.py:521\u001B[0m, in \u001B[0;36m_asarray_with_order\u001B[0;34m(array, dtype, order, copy, xp)\u001B[0m\n\u001B[1;32m    519\u001B[0m     array \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39marray(array, order\u001B[38;5;241m=\u001B[39morder, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m    520\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 521\u001B[0m     array \u001B[38;5;241m=\u001B[39m numpy\u001B[38;5;241m.\u001B[39masarray(array, order\u001B[38;5;241m=\u001B[39morder, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m    523\u001B[0m \u001B[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001B[39;00m\n\u001B[1;32m    524\u001B[0m \u001B[38;5;66;03m# container that is consistent with the input's namespace.\u001B[39;00m\n\u001B[1;32m    525\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39masarray(array)\n",
      "File \u001B[0;32m~/PycharmProjects/ml-hse/venv/lib/python3.11/site-packages/pandas/core/series.py:1021\u001B[0m, in \u001B[0;36mSeries.__array__\u001B[0;34m(self, dtype)\u001B[0m\n\u001B[1;32m    974\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    975\u001B[0m \u001B[38;5;124;03mReturn the values as a NumPy array.\u001B[39;00m\n\u001B[1;32m    976\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1018\u001B[0m \u001B[38;5;124;03m      dtype='datetime64[ns]')\u001B[39;00m\n\u001B[1;32m   1019\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1020\u001B[0m values \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_values\n\u001B[0;32m-> 1021\u001B[0m arr \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39masarray(values, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[1;32m   1022\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m using_copy_on_write() \u001B[38;5;129;01mand\u001B[39;00m astype_is_view(values\u001B[38;5;241m.\u001B[39mdtype, arr\u001B[38;5;241m.\u001B[39mdtype):\n\u001B[1;32m   1023\u001B[0m     arr \u001B[38;5;241m=\u001B[39m arr\u001B[38;5;241m.\u001B[39mview()\n",
      "\u001B[0;31mValueError\u001B[0m: could not convert string to float: 'Murray'"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB()\n",
    "data_train['class'] = gnb.fit(data_train['name'], data_train['sex']).predict(data_train['name'])\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (data_train['name'].shape[0], (data_train['sex'] != data_train['class']).sum()))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
